// Licensed to the LF AI & Data foundation under one
// or more contributor license agreements. See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership. The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License. You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

package models

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
	"sort"
	"time"
)


type EmbeddingRequest struct {
	// ID of the model to use. 
	Model string                  `json:"model"`

	// Input text to embed, encoded as a string.
	Input []string                `json:"input"`

	// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
	User string                   `json:"user,omitempty"`

	// The format to return the embeddings in. Can be either float or base64.
	EncodingFormat string         `json:"encoding_format,omitempty"`

	// The number of dimensions the resulting output embeddings should have. Only supported in text-embedding-3 and later models.
	Dimensions int                `json:"dimensions,omitempty"`
}

type Usage struct {
	// The number of tokens used by the prompt.
	PromptTokens     int `json:"prompt_tokens"`
	
	// The total number of tokens used by the request.
	TotalTokens      int `json:"total_tokens"`
}


type EmbeddingData struct {
	// The object type, which is always "embedding".
	Object    string    `json:"object"`

	// The embedding vector, which is a list of floats.
	Embedding []float32 `json:"embedding"`

	// The index of the embedding in the list of embeddings.
	Index     int       `json:"index"`
}


type EmbeddingResponse struct {
	// The object type, which is always "list".
	Object string          `json:"object"`

	// The list of embeddings generated by the model.
	Data []EmbeddingData   `json:"data"`

	// The name of the model used to generate the embedding.
	Model  string          `json:"model"`

	// The usage information for the request.
	Usage  Usage           `json:"usage"`
}


type ByIndex struct {
	resp *EmbeddingResponse
}

func (eb *ByIndex) Len() int           { return len(eb.resp.Data) }
func (eb *ByIndex) Swap(i, j int)      { eb.resp.Data[i], eb.resp.Data[j] = eb.resp.Data[j], eb.resp.Data[i] }
func (eb *ByIndex) Less(i, j int) bool { return eb.resp.Data[i].Index < eb.resp.Data[j].Index }


type ErrorInfo struct {
	Code string            `json:"code"`
	Message string         `json:"message"`
	Param string           `json:"param,omitempty"`
	Type  string           `json:"type"`
}

type EmbedddingError struct {
	Error ErrorInfo        `json:"error"`
}

type OpenAIEmbeddingClient struct {
	apiKey string
	url string
}

func (c *OpenAIEmbeddingClient) Check() error {
	if c.apiKey == "" {
		return fmt.Errorf("OpenAI api key is empty")
	}

	if c.url == "" {
		return fmt.Errorf("OpenAI embedding url is empty")
	}
	return nil
}

func NewOpenAIEmbeddingClient(apiKey string, url string) OpenAIEmbeddingClient{
	return OpenAIEmbeddingClient{
		apiKey: apiKey,
		url: url,
	}
}


func (c *OpenAIEmbeddingClient) send(client *http.Client, req *http.Request, res *EmbeddingResponse) error {
	// call openai
	resp, err := client.Do(req)
	
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	body, err := io.ReadAll(resp.Body)
	if err != nil {
		return err
	}

	if resp.StatusCode != 200 {
		return fmt.Errorf(string(body))
	}

	err = json.Unmarshal(body, &res)	
	if err != nil {
		return err
	}
	return nil
}

func (c *OpenAIEmbeddingClient) sendWithRetry(client *http.Client, req *http.Request,res *EmbeddingResponse, maxRetries int) error {
	var err error
	for i := 0; i < maxRetries; i++ {
		err = c.send(client, req, res)
		if err == nil {
			return nil
		}
	}
	return err
}

func (c *OpenAIEmbeddingClient) Embedding(modelName string, texts []string, dim int, user string, timeoutSec time.Duration) (*EmbeddingResponse, error) {
	var r EmbeddingRequest
	r.Model = modelName
	r.Input = texts
	r.EncodingFormat = "float"
	if user != "" {
		r.User = user
	}
	if dim != 0 {
		r.Dimensions = dim
	}

	data, err := json.Marshal(r)
	if err != nil {
		return nil, err
	}
	
	// call openai
	if timeoutSec <= 0 {
		timeoutSec = 30
	}
	client := &http.Client{
		Timeout: timeoutSec * time.Second,
	}
	req, err := http.NewRequest("POST" , c.url,  bytes.NewBuffer(data))
	if err != nil {
		return nil, err
	}
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("api-key", c.apiKey)

	var res EmbeddingResponse
	err = c.sendWithRetry(client, req, &res, 3)
	if err != nil {
		return nil, err
	}
	sort.Sort(&ByIndex{&res})
	return &res, err
	
}
